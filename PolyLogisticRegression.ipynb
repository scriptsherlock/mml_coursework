{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84a9a550",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# Polynomial Logistic Regression with Optuna tuning\n",
    "# Optimizes validation accuracy (60/20/20 split)\n",
    "# ============================================================\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.preprocessing import StandardScaler, PolynomialFeatures\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "import optuna\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# 1. Create or load your dataset\n",
    "# ------------------------------------------------------------\n",
    "n = 10\n",
    "\n",
    "X = np.load('Datasets/kryptonite-%s-X.npy'%(n))\n",
    "y = np.load('Datasets/kryptonite-%s-y.npy'%(n))\n",
    "\n",
    "# 60/20/20 split\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(\n",
    "    X, y, test_size=0.4, stratify=y, random_state=42\n",
    ")\n",
    "X_val, X_test, y_val, y_test = train_test_split(\n",
    "    X_temp, y_temp, test_size=0.5, stratify=y_temp, random_state=42\n",
    ")\n",
    "\n",
    "print(f\"Train: {len(X_train)}, Val: {len(X_val)}, Test: {len(X_test)}\")\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# 2. Define the Optuna objective\n",
    "# ------------------------------------------------------------\n",
    "def objective(trial):\n",
    "    # Hyperparameters to tune\n",
    "    degree = trial.suggest_int(\"degree\", 1, 4)\n",
    "    C = trial.suggest_float(\"C\", 1e-4, 1e3, log=True)\n",
    "    penalty = trial.suggest_categorical(\"penalty\", [\"l2\", \"l1\"])\n",
    "    solver = \"saga\" if penalty == \"l1\" else \"lbfgs\"\n",
    "\n",
    "    # Build pipeline: Polynomial → Standardize → Logistic Regression\n",
    "    model = Pipeline([\n",
    "        (\"poly\", PolynomialFeatures(degree=degree, include_bias=False)),\n",
    "        (\"scaler\", StandardScaler()),\n",
    "        (\"logreg\", LogisticRegression(\n",
    "            penalty=penalty,\n",
    "            C=C,\n",
    "            solver=solver,\n",
    "            max_iter=5000,\n",
    "            random_state=42))\n",
    "    ])\n",
    "\n",
    "    model.fit(X_train, y_train)\n",
    "    preds_val = model.predict(X_val)\n",
    "    acc = accuracy_score(y_val, preds_val)\n",
    "    return acc\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# 3. Run Optuna optimization\n",
    "# ------------------------------------------------------------\n",
    "study = optuna.create_study(direction=\"maximize\")\n",
    "study.optimize(objective, n_trials=40)\n",
    "\n",
    "best_trial = study.best_trial\n",
    "print(\"\\nBest Validation Results\")\n",
    "print(\"------------------------\")\n",
    "print(f\"Validation Accuracy: {best_trial.value:.4f}\")\n",
    "for k, v in best_trial.params.items():\n",
    "    print(f\"  {k}: {v}\")\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# 4. Retrain with best params on (Train + Val), test on Test Set\n",
    "# ------------------------------------------------------------\n",
    "def train_full_and_test(params):\n",
    "    degree = params[\"degree\"]\n",
    "    C = params[\"C\"]\n",
    "    penalty = params[\"penalty\"]\n",
    "    solver = \"saga\" if penalty == \"l1\" else \"lbfgs\"\n",
    "\n",
    "    model = Pipeline([\n",
    "        (\"poly\", PolynomialFeatures(degree=degree, include_bias=False)),\n",
    "        (\"scaler\", StandardScaler()),\n",
    "        (\"logreg\", LogisticRegression(\n",
    "            penalty=penalty,\n",
    "            C=C,\n",
    "            solver=solver,\n",
    "            max_iter=5000,\n",
    "            random_state=42))\n",
    "    ])\n",
    "\n",
    "    # Train on 80% (train + val)\n",
    "    X_combined = np.vstack([X_train, X_val])\n",
    "    y_combined = np.concatenate([y_train, y_val])\n",
    "    model.fit(X_combined, y_combined)\n",
    "\n",
    "    preds_test = model.predict(X_test)\n",
    "    test_acc = accuracy_score(y_test, preds_test)\n",
    "    return test_acc\n",
    "\n",
    "test_acc = train_full_and_test(best_trial.params)\n",
    "print(\"\\nFinal Test Accuracy (using best params): {:.4f}\".format(test_acc))\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
